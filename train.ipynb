{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853686eb-986c-4fc7-b505-45c5fd23b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e65002a7-b325-49cb-9be1-d8e440292248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Total records: 2619041\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-04-05</td>\n",
       "      <td>AALI</td>\n",
       "      <td>571.710632</td>\n",
       "      <td>571.710632</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>248.808121</td>\n",
       "      <td>57721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-04-06</td>\n",
       "      <td>AALI</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>248.808121</td>\n",
       "      <td>83433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-04-09</td>\n",
       "      <td>AALI</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>248.808121</td>\n",
       "      <td>10494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-04-10</td>\n",
       "      <td>AALI</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>248.808121</td>\n",
       "      <td>352625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-04-11</td>\n",
       "      <td>AALI</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>547.889343</td>\n",
       "      <td>248.808121</td>\n",
       "      <td>59295.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker        Open        High         Low       Close  \\\n",
       "0 2001-04-05   AALI  571.710632  571.710632  547.889343  547.889343   \n",
       "1 2001-04-06   AALI  547.889343  547.889343  547.889343  547.889343   \n",
       "2 2001-04-09   AALI  547.889343  547.889343  547.889343  547.889343   \n",
       "3 2001-04-10   AALI  547.889343  547.889343  547.889343  547.889343   \n",
       "4 2001-04-11   AALI  547.889343  547.889343  547.889343  547.889343   \n",
       "\n",
       "    Adj Close    Volume  \n",
       "0  248.808121   57721.0  \n",
       "1  248.808121   83433.0  \n",
       "2  248.808121   10494.0  \n",
       "3  248.808121  352625.0  \n",
       "4  248.808121   59295.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('idx.csv', parse_dates=['Date'])\n",
    "\n",
    "# Sort\n",
    "df.sort_values(['Ticker', 'Date'], inplace=True)\n",
    "\n",
    "# missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Reset\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print\n",
    "print('Data loaded successfully.')\n",
    "print(f'Total records: {len(df)}')\n",
    "print('Sample data:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f86c8e-ffce-4af9-ba1f-9003a272a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_ticker(ticker, df):\n",
    "    ticker_data = df[df['Ticker'] == ticker].copy()\n",
    "    ticker_data.sort_values('Date', inplace=True)\n",
    "    ticker_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Check if there's enough data\n",
    "    if len(ticker_data) < 10:\n",
    "        return None, None\n",
    "\n",
    "    # Create lag features\n",
    "    for lag in range(1, 6):\n",
    "        ticker_data[f'lag_{lag}'] = ticker_data['Close'].shift(lag)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    ticker_data.dropna(inplace=True)\n",
    "    \n",
    "    # Features and target\n",
    "    X = ticker_data[[f'lag_{lag}' for lag in range(1, 6)]]\n",
    "    y = ticker_data['Close']\n",
    "\n",
    "    # If less than 10 data after dropna, it will not count\n",
    "    if len(X) < 10:\n",
    "        return None, None\n",
    "\n",
    "    # Split training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Train Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate MSE on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return model, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100c1b69-d1f1-4d83-88a4-0354ea00d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_5_closing_prices(ticker, df):\n",
    "    ticker_data = df[df['Ticker'] == ticker].copy()\n",
    "    ticker_data.sort_values('Date', inplace=True)\n",
    "    return ticker_data['Close'].iloc[-5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc9752d-950b-4e7c-892c-e96210a0efa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for AALI, MSE: 45033.5029\n",
      "Model trained for ABBA, MSE: 97.0269\n",
      "Model trained for ABDA, MSE: 13851.7374\n",
      "Model trained for ABMM, MSE: 8981.6788\n",
      "Model trained for ACES, MSE: 620.7367\n",
      "Model trained for ACRO, MSE: 11.8087\n",
      "Model trained for ACST, MSE: 24.2007\n",
      "Model trained for ADCP, MSE: 0.5640\n",
      "Model trained for ADES, MSE: 29448.9677\n",
      "Model trained for ADHI, MSE: 603.3303\n",
      "Model trained for ADMF, MSE: 20311.5384\n",
      "Model trained for ADMG, MSE: 24.7557\n",
      "Model trained for ADMR, MSE: 1585.1430\n",
      "Model trained for ADRO, MSE: 4620.1014\n",
      "Model trained for AEGS, MSE: 12.2448\n",
      "Model trained for AGAR, MSE: 16.1595\n",
      "Model trained for AGII, MSE: 1373.7862\n",
      "Model trained for AGRO, MSE: 2134.1315\n",
      "Model trained for AGRS, MSE: 4.2137\n",
      "Model trained for AHAP, MSE: 14.2690\n",
      "Model trained for AIMS, MSE: 396.1722\n",
      "Model trained for AISA, MSE: 42.2029\n",
      "Model trained for AKKU, MSE: 0.1214\n",
      "Model trained for AKPI, MSE: 911.5030\n",
      "Model trained for AKRA, MSE: 750.4242\n",
      "Model trained for AKSI, MSE: 578.3440\n",
      "Model trained for ALDO, MSE: 1186.3903\n",
      "Model trained for ALII, MSE: 307.2544\n",
      "Model trained for ALKA, MSE: 555.8873\n",
      "Model trained for ALMI, MSE: 135.2826\n",
      "Model trained for ALTO, MSE: 39.1990\n",
      "Model trained for AMAG, MSE: 46.3016\n",
      "Model trained for AMAN, MSE: 37.0512\n",
      "Model trained for AMAR, MSE: 36.7336\n",
      "Model trained for AMFG, MSE: 11915.4318\n",
      "Model trained for AMIN, MSE: 33.1241\n",
      "Model trained for AMMN, MSE: 27823.1764\n",
      "Model trained for AMMS, MSE: 1.2344\n",
      "Model trained for AMOR, MSE: 734.2312\n",
      "Model trained for AMRT, MSE: 2423.2648\n",
      "Model trained for ANDI, MSE: 0.5134\n",
      "Model trained for ANJT, MSE: 222.0558\n",
      "Model trained for ANTM, MSE: 5612.9818\n",
      "Model trained for APEX, MSE: 749.1921\n",
      "Model trained for APIC, MSE: 299.6599\n",
      "Model trained for APII, MSE: 21.9953\n",
      "Model trained for APLI, MSE: 141.5622\n",
      "Model trained for APLN, MSE: 11.4131\n",
      "Model trained for ARCI, MSE: 166.8486\n",
      "Model trained for AREA, MSE: 260.3414\n",
      "Model trained for ARGO, MSE: 178.1335\n",
      "Model trained for ARII, MSE: 159.4200\n",
      "Model trained for ARKA, MSE: 0.4138\n",
      "Model trained for ARKO, MSE: 1742.7036\n",
      "Model trained for ARMY, MSE: 0.0085\n",
      "Model trained for ARNA, MSE: 184.6479\n",
      "Model trained for ARTA, MSE: 2644.4623\n",
      "Model trained for ARTI, MSE: 0.5855\n",
      "Model trained for ARTO, MSE: 25563.2084\n",
      "Model trained for ASBI, MSE: 325.4365\n",
      "Model trained for ASDM, MSE: 74.8912\n",
      "Model trained for ASGR, MSE: 140.2718\n",
      "Model trained for ASHA, MSE: 0.9889\n",
      "Model trained for ASII, MSE: 13650.9550\n",
      "Model trained for ASJT, MSE: 20.5861\n",
      "Model trained for ASLC, MSE: 12.0594\n",
      "Model trained for ASLI, MSE: 0.0001\n",
      "Model trained for ASMI, MSE: 25.4468\n",
      "Model trained for ASPI, MSE: 160.6381\n",
      "Model trained for ASRI, MSE: 15.4841\n",
      "Model trained for ASRM, MSE: 1019.2032\n",
      "Model trained for ASSA, MSE: 3428.4749\n",
      "Model trained for ATAP, MSE: 5.5519\n",
      "Model trained for ATIC, MSE: 248.0066\n",
      "Model trained for ATLA, MSE: 355.7930\n",
      "Model trained for AUTO, MSE: 1526.2960\n",
      "Model trained for AVIA, MSE: 192.9340\n",
      "Model trained for AWAN, MSE: 51.3572\n",
      "Model trained for AXIO, MSE: 15.0512\n",
      "Model trained for AYAM, MSE: 7.1301\n",
      "Model trained for AYLS, MSE: 2.3986\n",
      "Model trained for BABP, MSE: 77.5375\n",
      "Model trained for BABY, MSE: 76.4520\n",
      "Model trained for BACA, MSE: 171.3304\n",
      "Model trained for BAIK, MSE: 2.7829\n",
      "Model trained for BAJA, MSE: 55.0426\n",
      "Model trained for BALI, MSE: 1246.4707\n",
      "Model trained for BANK, MSE: 1657.4506\n",
      "Model trained for BAPA, MSE: 20.5925\n",
      "Model trained for BAPI, MSE: 0.0004\n",
      "Model trained for BATA, MSE: 410.5022\n",
      "Model trained for BAUT, MSE: 2.5541\n",
      "Model trained for BAYU, MSE: 1432.1483\n",
      "Model trained for BBCA, MSE: 11950.2125\n",
      "Model trained for BBHI, MSE: 4233.4692\n",
      "Model trained for BBKP, MSE: 94.5166\n",
      "Model trained for BBLD, MSE: 304.1255\n",
      "Model trained for BBMD, MSE: 1159.4860\n",
      "Model trained for BBNI, MSE: 5271.5582\n",
      "Model trained for BBRI, MSE: 6685.8747\n",
      "Model trained for BBRM, MSE: 5.3549\n",
      "Model trained for BBSI, MSE: 11477.8635\n",
      "Model trained for BBSS, MSE: 33.5332\n",
      "Model trained for BBTN, MSE: 667.3649\n",
      "Model trained for BBYB, MSE: 775.2686\n",
      "Model trained for BCAP, MSE: 38.1050\n",
      "Model trained for BCIC, MSE: 22498110609.7849\n",
      "Model trained for BCIP, MSE: 6.2405\n",
      "Model trained for BDKR, MSE: 80.6898\n",
      "Model trained for BDMN, MSE: 3505.7935\n",
      "Model trained for BEBS, MSE: 4.7501\n",
      "Model trained for BEEF, MSE: 50.0292\n",
      "Model trained for BEER, MSE: 65.8334\n",
      "Model trained for BEKS, MSE: 4.7062\n",
      "Model trained for BELI, MSE: 5.1859\n",
      "Model trained for BELL, MSE: 15.2355\n",
      "Model trained for BESS, MSE: 40.0672\n",
      "Model trained for BEST, MSE: 8.8807\n",
      "Model trained for BFIN, MSE: 691.8851\n",
      "Model trained for BGTG, MSE: 5.0563\n",
      "Model trained for BHAT, MSE: 140.0814\n",
      "Model trained for BHIT, MSE: 5.8959\n",
      "Model trained for BIKA, MSE: 11.7625\n",
      "Model trained for BIKE, MSE: 294.7476\n",
      "Model trained for BIMA, MSE: 76.1859\n",
      "Model trained for BINA, MSE: 2335.5976\n",
      "Model trained for BINO, MSE: 1.3606\n",
      "Model trained for BIPI, MSE: 20.3105\n",
      "Model trained for BIPP, MSE: 1.8585\n",
      "Model trained for BIRD, MSE: 1855.1712\n",
      "Model trained for BISI, MSE: 875.6316\n",
      "Model trained for BJBR, MSE: 221.2585\n",
      "Model trained for BJTM, MSE: 42.4085\n",
      "Model trained for BKDP, MSE: 8.8328\n",
      "Model trained for BKSL, MSE: 0.9373\n",
      "Model trained for BKSW, MSE: 54.7238\n",
      "Model trained for BLTA, MSE: 0.1964\n",
      "Model trained for BLTZ, MSE: 18147.1997\n",
      "Model trained for BLUE, MSE: 124.2330\n",
      "Model trained for BMAS, MSE: 518.3916\n",
      "Model trained for BMBL, MSE: 1.0558\n",
      "Model trained for BMHS, MSE: 35.8422\n",
      "Model trained for BMRI, MSE: 6812.0739\n",
      "Model trained for BMSR, MSE: 416.3161\n",
      "Model trained for BMTR, MSE: 61.7247\n",
      "Model trained for BNBA, MSE: 6343.6390\n",
      "Model trained for BNBR, MSE: 13072.9015\n",
      "Model trained for BNGA, MSE: 482.7540\n",
      "Model trained for BNII, MSE: 59.6444\n",
      "Model trained for BNLI, MSE: 2390.7537\n",
      "Model trained for BOBA, MSE: 11.7843\n",
      "Model trained for BOGA, MSE: 311.3115\n",
      "Model trained for BOLA, MSE: 25.4208\n",
      "Model trained for BOLT, MSE: 472.9210\n",
      "Model trained for BORN, MSE: 0.0415\n",
      "Model trained for BOSS, MSE: 2.3019\n",
      "Model trained for BPFI, MSE: 534.6788\n",
      "Model trained for BPII, MSE: 44.0700\n",
      "Model trained for BPTR, MSE: 22.2141\n",
      "Model trained for BRAM, MSE: 99931.3890\n",
      "Model trained for BREN, MSE: 234381.1787\n",
      "Model trained for BRIS, MSE: 2979.8220\n",
      "Model trained for BRMS, MSE: 37.3795\n",
      "Model trained for BRNA, MSE: 1283.4347\n",
      "Model trained for BRPT, MSE: 1437.8445\n",
      "Model trained for BSBK, MSE: 1.8333\n",
      "Model trained for BSDE, MSE: 339.1003\n",
      "Model trained for BSIM, MSE: 328.3195\n",
      "Model trained for BSML, MSE: 97.2642\n",
      "Model trained for BSSR, MSE: 9683.8416\n",
      "Model trained for BSWD, MSE: 327.4494\n",
      "Model trained for BTEK, MSE: 0.2256\n",
      "Model trained for BTEL, MSE: 0.0032\n",
      "Model trained for BTON, MSE: 94.9029\n",
      "Model trained for BTPN, MSE: 736.6718\n",
      "Model trained for BTPS, MSE: 2037.1813\n",
      "Model trained for BUAH, MSE: 4461.6202\n",
      "Model trained for BUDI, MSE: 26.5218\n",
      "Model trained for BUKA, MSE: 19.6151\n",
      "Model trained for BUKK, MSE: 1272.6003\n",
      "Model trained for BULL, MSE: 26.5035\n",
      "Model trained for BUMI, MSE: 16.0800\n",
      "Model trained for BUVA, MSE: 1.2167\n",
      "Model trained for BVIC, MSE: 33.6034\n",
      "Model trained for BWPT, MSE: 3.2109\n",
      "Model trained for BYAN, MSE: 125483.0643\n",
      "Model trained for CAKK, MSE: 30.7224\n",
      "Model trained for CAMP, MSE: 49.4341\n",
      "Model trained for CANI, MSE: 14.5570\n",
      "Model trained for CARE, MSE: 213.4630\n",
      "Model trained for CARS, MSE: 5.8149\n",
      "Model trained for CASA, MSE: 220.4249\n",
      "Model trained for CASH, MSE: 25.3257\n",
      "Model trained for CASS, MSE: 470.4141\n",
      "Model trained for CBMF, MSE: 0.0497\n",
      "Model trained for CBPE, MSE: 16.1431\n",
      "Model trained for CBRE, MSE: 10.1520\n",
      "Model trained for CBUT, MSE: 10291.3954\n",
      "Model trained for CCSI, MSE: 254.4199\n",
      "Model trained for CEKA, MSE: 932.8956\n",
      "Model trained for CENT, MSE: 46.5485\n",
      "Model trained for CFIN, MSE: 106.9571\n",
      "Model trained for CGAS, MSE: 50.2006\n",
      "Model trained for CHEM, MSE: 25.4270\n",
      "Model trained for CHIP, MSE: 1096.2804\n",
      "Model trained for CINT, MSE: 29.9611\n",
      "Model trained for CITA, MSE: 6092.1755\n",
      "Model trained for CITY, MSE: 18.5333\n",
      "Model trained for CKRA, MSE: 7.2305\n",
      "Model trained for CLAY, MSE: 74.2754\n",
      "Model trained for CLEO, MSE: 320.2305\n",
      "Model trained for CLPI, MSE: 173.0484\n",
      "Model trained for CMNP, MSE: 2225.3448\n",
      "Model trained for CMNT, MSE: 416.1294\n",
      "Model trained for CMPP, MSE: 141.6287\n",
      "Model trained for CMRY, MSE: 7831.9659\n",
      "Model trained for CNKO, MSE: 0.1450\n",
      "Model trained for CNMA, MSE: 26.5588\n",
      "Model trained for CNTB, MSE: 0.0000\n",
      "Model trained for CNTX, MSE: 104.0048\n",
      "Model trained for COAL, MSE: 0.2128\n",
      "Model trained for COCO, MSE: 58.1496\n",
      "Model trained for COWL, MSE: 0.0310\n",
      "Model trained for CPIN, MSE: 15175.0529\n",
      "Model trained for CPRI, MSE: 0.0116\n",
      "Model trained for CPRO, MSE: 5.0668\n",
      "Model trained for CRAB, MSE: 53.8161\n",
      "Model trained for CRSN, MSE: 4.4970\n",
      "Model trained for CSAP, MSE: 257.2012\n",
      "Model trained for CSIS, MSE: 4.5245\n",
      "Model trained for CSMI, MSE: 1949.5923\n",
      "Model trained for CSRA, MSE: 91.4101\n",
      "Model trained for CTBN, MSE: 12678.1000\n",
      "Model trained for CTRA, MSE: 632.6717\n",
      "Model trained for CTTH, MSE: 2.1907\n",
      "Model trained for CUAN, MSE: 198992.7836\n",
      "Model trained for CYBR, MSE: 396.8494\n",
      "Model trained for DADA, MSE: 0.8532\n",
      "Model trained for DART, MSE: 236.5164\n",
      "Insufficient data to train model for DATA.\n",
      "Model trained for DAYA, MSE: 83.2574\n",
      "Model trained for DCII, MSE: 3112522.4341\n",
      "Model trained for DEAL, MSE: 1.1247\n",
      "Model trained for DEFI, MSE: 821.6547\n",
      "Model trained for DEPO, MSE: 56.0120\n",
      "Model trained for DEWA, MSE: 3.9463\n",
      "Model trained for DEWI, MSE: 4.2411\n",
      "Model trained for DFAM, MSE: 5.6573\n",
      "Model trained for DGIK, MSE: 17.6769\n",
      "Model trained for DGNS, MSE: 147.5612\n",
      "Model trained for DIGI, MSE: 2.3876\n",
      "Model trained for DILD, MSE: 31.7411\n",
      "Model trained for DIVA, MSE: 475.2320\n",
      "Model trained for DKFT, MSE: 14.2581\n",
      "Model trained for DLTA, MSE: 4418.9447\n",
      "Model trained for DMAS, MSE: 3.5287\n",
      "Model trained for DMMX, MSE: 328.5232\n",
      "Model trained for DMND, MSE: 57.2280\n",
      "Model trained for DNAR, MSE: 16.7821\n",
      "Model trained for DNET, MSE: 3146.6820\n",
      "Model trained for DOID, MSE: 150.5047\n",
      "Model trained for DOOH, MSE: 11.4445\n",
      "Model trained for DPNS, MSE: 68.0914\n",
      "Model trained for DPUM, MSE: 1.0664\n",
      "Model trained for DRMA, MSE: 1520.7693\n",
      "Model trained for DSFI, MSE: 6.9198\n",
      "Model trained for DSNG, MSE: 217.3176\n",
      "Model trained for DSSA, MSE: 5070151.7738\n",
      "Model trained for DUCK, MSE: 0.0167\n",
      "Model trained for DUTI, MSE: 12153.7920\n",
      "Model trained for DVLA, MSE: 1781.9732\n",
      "Model trained for DWGL, MSE: 38.0320\n",
      "Model trained for DYAN, MSE: 6.9586\n",
      "Model trained for EAST, MSE: 10.0071\n",
      "Model trained for ECII, MSE: 188.4752\n",
      "Model trained for EDGE, MSE: 108473.5942\n",
      "Model trained for EKAD, MSE: 8.9326\n",
      "Model trained for ELIT, MSE: 10.7092\n",
      "Model trained for ELPI, MSE: 47.7038\n",
      "Model trained for ELSA, MSE: 55.6514\n",
      "Model trained for ELTY, MSE: 24.8912\n",
      "Model trained for EMDE, MSE: 16.3518\n",
      "Model trained for EMTK, MSE: 2994.4150\n",
      "Model trained for ENAK, MSE: 783.1154\n",
      "Model trained for ENRG, MSE: 57.0220\n",
      "Model trained for ENVY, MSE: 0.1636\n",
      "Model trained for ENZO, MSE: 1.9560\n",
      "Model trained for EPAC, MSE: 0.3077\n",
      "Model trained for EPMT, MSE: 1073.1014\n",
      "Model trained for ERAA, MSE: 114.6550\n",
      "Model trained for ERAL, MSE: 74.3425\n",
      "Model trained for ERTX, MSE: 135.0732\n",
      "Model trained for ESIP, MSE: 2.2829\n",
      "Model trained for ESSA, MSE: 1228.0026\n",
      "Model trained for ESTA, MSE: 6.4177\n",
      "Model trained for ESTI, MSE: 8.0724\n",
      "Model trained for ETWA, MSE: 30.9179\n",
      "Model trained for EURO, MSE: 56.5306\n",
      "Model trained for EXCL, MSE: 3540.9323\n",
      "Model trained for FAPA, MSE: 441.6499\n",
      "Model trained for FAST, MSE: 365.9632\n",
      "Model trained for FASW, MSE: 8908.8328\n",
      "Model trained for FILM, MSE: 22127.0594\n",
      "Model trained for FIMP, MSE: 6.0110\n",
      "Model trained for FIRE, MSE: 79.4120\n",
      "Model trained for FISH, MSE: 51975.6050\n",
      "Model trained for FITT, MSE: 163.8870\n",
      "Model trained for FLMC, MSE: 1.8880\n",
      "Model trained for FMII, MSE: 233.1039\n",
      "Model trained for FOLK, MSE: 6.1093\n",
      "Model trained for FOOD, MSE: 28.6219\n",
      "Model trained for FORU, MSE: 179.4363\n",
      "Model trained for FORZ, MSE: 0.0622\n",
      "Model trained for FPNI, MSE: 103.1876\n",
      "Model trained for FREN, MSE: 7.8871\n",
      "Model trained for FUJI, MSE: 81.9789\n",
      "Model trained for FUTR, MSE: 0.0010\n",
      "Model trained for FWCT, MSE: 62.1956\n",
      "Model trained for GAMA, MSE: 0.0912\n",
      "Model trained for GDST, MSE: 31.5798\n",
      "Model trained for GDYR, MSE: 1836.5561\n",
      "Model trained for GEMA, MSE: 96.1670\n",
      "Model trained for GEMS, MSE: 32305.7101\n",
      "Model trained for GGRM, MSE: 874843.3579\n",
      "Model trained for GGRP, MSE: 96.1558\n",
      "Model trained for GHON, MSE: 699.4716\n",
      "Model trained for GIAA, MSE: 5.6992\n",
      "Model trained for GJTL, MSE: 581.9569\n",
      "Model trained for GLOB, MSE: 34.0931\n",
      "Model trained for GLVA, MSE: 1419.2120\n",
      "Model trained for GMFI, MSE: 4.1990\n",
      "Model trained for GMTD, MSE: 2970.4168\n",
      "Model trained for GOLD, MSE: 309.7293\n",
      "Model trained for GOLL, MSE: 0.0198\n",
      "Model trained for GOOD, MSE: 18.2198\n",
      "Model trained for GOTO, MSE: 19.2703\n",
      "Model trained for GPRA, MSE: 4.9904\n",
      "Model trained for GPSO, MSE: 103.4864\n",
      "Model trained for GRIA, MSE: 40.6512\n",
      "Model trained for GRPH, MSE: 0.0032\n",
      "Model trained for GRPM, MSE: 0.7652\n",
      "Model trained for GSMF, MSE: 30.9869\n",
      "Model trained for GTBO, MSE: 386.3729\n",
      "Model trained for GTRA, MSE: 98.2473\n",
      "Model trained for GTSI, MSE: 0.1932\n",
      "Model trained for GULA, MSE: 107.6691\n",
      "Model trained for GWSA, MSE: 12.6887\n",
      "Model trained for GZCO, MSE: 30.4923\n",
      "Model trained for HADE, MSE: 0.2382\n",
      "Model trained for HAIS, MSE: 34.7472\n",
      "Model trained for HAJJ, MSE: 14.0414\n",
      "Model trained for HALO, MSE: 0.0194\n",
      "Model trained for HATM, MSE: 49.6546\n",
      "Model trained for HBAT, MSE: 1.6527\n",
      "Model trained for HDFA, MSE: 79.6601\n",
      "Model trained for HDIT, MSE: 1.4528\n",
      "Model trained for HDTX, MSE: 0.6810\n",
      "Model trained for HEAL, MSE: 716.5211\n",
      "Model trained for HELI, MSE: 181.4649\n",
      "Model trained for HERO, MSE: 1341.9146\n",
      "Model trained for HEXA, MSE: 7098.8767\n",
      "Model trained for HILL, MSE: 13706.0831\n",
      "Model trained for HITS, MSE: 743.3294\n",
      "Model trained for HKMU, MSE: 0.0395\n",
      "Model trained for HMSP, MSE: 897.7340\n",
      "Model trained for HOKI, MSE: 26.4299\n",
      "Model trained for HOME, MSE: 0.1005\n",
      "Model trained for HOMI, MSE: 304.3022\n",
      "Model trained for HOPE, MSE: 3.6826\n",
      "Model trained for HOTL, MSE: 0.0346\n",
      "Model trained for HRME, MSE: 0.3927\n",
      "Model trained for HRTA, MSE: 182.6330\n",
      "Model trained for HRUM, MSE: 3206.0845\n",
      "Model trained for HUMI, MSE: 15.1188\n",
      "Model trained for HYGN, MSE: 50.5862\n",
      "Model trained for IATA, MSE: 26.9172\n",
      "Model trained for IBFN, MSE: 14.2337\n",
      "Model trained for IBOS, MSE: 1384.6673\n",
      "Model trained for IBST, MSE: 68525.8109\n",
      "Model trained for ICBP, MSE: 29932.0107\n",
      "Model trained for ICON, MSE: 11.8155\n",
      "Model trained for IDEA, MSE: 3.9463\n",
      "Model trained for IDPR, MSE: 17.7123\n",
      "Model trained for IFII, MSE: 15.0241\n",
      "Model trained for IFSH, MSE: 572.8796\n",
      "Model trained for IGAR, MSE: 64.4832\n",
      "Model trained for IIKP, MSE: 0.0226\n",
      "Model trained for IKAI, MSE: 3.3676\n",
      "Model trained for IKAN, MSE: 0.5874\n",
      "Model trained for IKBI, MSE: 222.5487\n",
      "Model trained for IKPM, MSE: 439.6378\n",
      "Model trained for IMAS, MSE: 2232.6990\n",
      "Model trained for IMJS, MSE: 89.5104\n",
      "Model trained for IMPC, MSE: 47.1127\n",
      "Model trained for INAF, MSE: 8863.2737\n",
      "Model trained for INAI, MSE: 72.4720\n",
      "Model trained for INCF, MSE: 86.4857\n",
      "Model trained for INCI, MSE: 233.8842\n",
      "Model trained for INCO, MSE: 22752.4528\n",
      "Model trained for INDF, MSE: 13236.8336\n",
      "Model trained for INDO, MSE: 3.9873\n",
      "Model trained for INDR, MSE: 28526.9649\n",
      "Model trained for INDS, MSE: 3242.6082\n",
      "Model trained for INDX, MSE: 120.7053\n",
      "Model trained for INDY, MSE: 4169.8161\n",
      "Model trained for INET, MSE: 2.5210\n",
      "Model trained for INKP, MSE: 66068.5492\n",
      "Model trained for INOV, MSE: 15.9956\n",
      "Model trained for INPC, MSE: 33.4602\n",
      "Model trained for INPP, MSE: 503.9613\n",
      "Model trained for INPS, MSE: 308.9156\n",
      "Model trained for INRU, MSE: 1005.2180\n",
      "Model trained for INTA, MSE: 30.5229\n",
      "Model trained for INTD, MSE: 166.2677\n",
      "Model trained for INTP, MSE: 96234.5170\n",
      "Model trained for IOTF, MSE: 312.2425\n",
      "Model trained for IPAC, MSE: 14.8145\n",
      "Model trained for IPCC, MSE: 148.2390\n",
      "Model trained for IPCM, MSE: 6.5012\n",
      "Model trained for IPOL, MSE: 10.2193\n",
      "Model trained for IPPE, MSE: 2.6120\n",
      "Model trained for IPTV, MSE: 2.9988\n",
      "Model trained for IRRA, MSE: 753.7311\n",
      "Model trained for IRSX, MSE: 0.2139\n",
      "Model trained for ISAP, MSE: 0.6392\n",
      "Model trained for ISAT, MSE: 31421.9731\n",
      "Model trained for ISSP, MSE: 39.1179\n",
      "Model trained for ITIC, MSE: 34.6388\n",
      "Model trained for ITMA, MSE: 787.0991\n",
      "Model trained for ITMG, MSE: 493826.2094\n",
      "Model trained for ITTG, MSE: 0.0300\n",
      "Model trained for JARR, MSE: 596.7238\n",
      "Model trained for JAST, MSE: 0.9688\n",
      "Model trained for JATI, MSE: 0.0259\n",
      "Model trained for JAWA, MSE: 66.4691\n",
      "Model trained for JAYA, MSE: 7.6128\n",
      "Model trained for JECC, MSE: 44569.0649\n",
      "Model trained for JGLE, MSE: 0.2510\n",
      "Model trained for JIHD, MSE: 146.6618\n",
      "Model trained for JKON, MSE: 24.9377\n",
      "Model trained for JKSW, MSE: 0.0410\n",
      "Model trained for JMAS, MSE: 9.6262\n",
      "Model trained for JPFA, MSE: 1362.6036\n",
      "Model trained for JRPT, MSE: 41.0491\n",
      "Model trained for JSKY, MSE: 0.7213\n",
      "Model trained for JSMR, MSE: 6357.2597\n",
      "Model trained for JSPT, MSE: 704.6133\n",
      "Model trained for JTPE, MSE: 32.0501\n",
      "Model trained for KAEF, MSE: 10020.6156\n",
      "Model trained for KARW, MSE: 30.3576\n",
      "Model trained for KAYU, MSE: 270.1515\n",
      "Model trained for KBAG, MSE: 0.3787\n",
      "Model trained for KBLI, MSE: 43.9042\n",
      "Model trained for KBLM, MSE: 89.6689\n",
      "Model trained for KBLV, MSE: 509.5459\n",
      "Model trained for KBRI, MSE: 0.0000\n",
      "Model trained for KDSI, MSE: 981.5048\n",
      "Model trained for KDTN, MSE: 7.6258\n",
      "Model trained for KEEN, MSE: 568.6512\n",
      "Model trained for KEJU, MSE: 410.0076\n",
      "Model trained for KETR, MSE: 64.5765\n",
      "Model trained for KIAS, MSE: 1.8592\n",
      "Model trained for KICI, MSE: 123.0520\n",
      "Model trained for KIJA, MSE: 15.8580\n",
      "Model trained for KING, MSE: 17.3968\n",
      "Model trained for KINO, MSE: 819.5092\n",
      "Model trained for KIOS, MSE: 9.8037\n",
      "Model trained for KJEN, MSE: 24.2164\n",
      "Model trained for KKES, MSE: 0.0001\n",
      "Model trained for KKGI, MSE: 171.1133\n",
      "Model trained for KLAS, MSE: 7.7306\n",
      "Model trained for KLBF, MSE: 1150.9086\n",
      "Model trained for KLIN, MSE: 0.8555\n",
      "Model trained for KMDS, MSE: 34.1290\n",
      "Model trained for KMTR, MSE: 62.1868\n",
      "Model trained for KOBX, MSE: 148.6303\n",
      "Model trained for KOCI, MSE: 1.4116\n",
      "Model trained for KOIN, MSE: 16.4279\n",
      "Model trained for KOKA, MSE: 29.9409\n",
      "Model trained for KONI, MSE: 9445.2055\n",
      "Model trained for KOPI, MSE: 1610.0843\n",
      "Model trained for KOTA, MSE: 0.5929\n",
      "Model trained for KPAL, MSE: 0.4072\n",
      "Model trained for KPAS, MSE: 0.0075\n",
      "Model trained for KPIG, MSE: 12.0409\n",
      "Model trained for KRAH, MSE: 0.0028\n",
      "Model trained for KRAS, MSE: 54.7744\n",
      "Model trained for KREN, MSE: 31.1427\n",
      "Model trained for KRYA, MSE: 6.9974\n",
      "Model trained for KUAS, MSE: 0.7791\n",
      "Model trained for LABA, MSE: 20.7598\n",
      "Model trained for LAJU, MSE: 1.7590\n",
      "Model trained for LAND, MSE: 0.8561\n",
      "Model trained for LAPD, MSE: 0.2517\n",
      "Model trained for LCGP, MSE: 0.0009\n",
      "Model trained for LCKM, MSE: 43.3265\n",
      "Model trained for LEAD, MSE: 7.6919\n",
      "Model trained for LFLO, MSE: 5.7080\n",
      "Model trained for LIFE, MSE: 168.3961\n",
      "Model trained for LINK, MSE: 4100.2302\n",
      "Model trained for LION, MSE: 465.2282\n",
      "Model trained for LIVE, MSE: 71.8607\n",
      "Model trained for LMAS, MSE: 35.5102\n",
      "Model trained for LMAX, MSE: 14.2372\n",
      "Model trained for LMPI, MSE: 23.0992\n",
      "Model trained for LMSH, MSE: 716.3310\n",
      "Model trained for LOPI, MSE: 5.9065\n",
      "Model trained for LPCK, MSE: 905.2696\n",
      "Model trained for LPGI, MSE: 8468.9618\n",
      "Model trained for LPIN, MSE: 541.1804\n",
      "Model trained for LPKR, MSE: 18.4104\n",
      "Model trained for LPLI, MSE: 92.4147\n",
      "Model trained for LPPF, MSE: 14248.9799\n",
      "Model trained for LPPS, MSE: 4.4940\n",
      "Model trained for LRNA, MSE: 37.3899\n",
      "Model trained for LSIP, MSE: 684.6491\n",
      "Model trained for LTLS, MSE: 560.8694\n",
      "Model trained for LUCK, MSE: 3.2682\n",
      "Model trained for LUCY, MSE: 11.2173\n",
      "Model trained for MABA, MSE: 0.4285\n",
      "Model trained for MAGP, MSE: 0.0001\n",
      "Model trained for MAHA, MSE: 30.5612\n",
      "Model trained for MAIN, MSE: 1004.6366\n",
      "Model trained for MAMI, MSE: 25.1062\n",
      "Model trained for MANG, MSE: 223.6455\n",
      "Model trained for MAPA, MSE: 456.0765\n",
      "Model trained for MAPB, MSE: 2892.0964\n",
      "Model trained for MAPI, MSE: 1363.1611\n",
      "Model trained for MARI, MSE: 24.5922\n",
      "Model trained for MARK, MSE: 362.6063\n",
      "Model trained for MASA, MSE: 22137.2898\n",
      "Model trained for MASB, MSE: 1885.3215\n",
      "Model trained for MAXI, MSE: 0.0093\n",
      "Model trained for MAYA, MSE: 2220.2294\n",
      "Model trained for MBAP, MSE: 25587.1684\n",
      "Model trained for MBMA, MSE: 444.8305\n",
      "Model trained for MBSS, MSE: 1374.5582\n",
      "Model trained for MBTO, MSE: 18.1559\n",
      "Model trained for MCAS, MSE: 31182.4989\n",
      "Model trained for MCOL, MSE: 9563.7443\n",
      "Model trained for MCOR, MSE: 8.9035\n",
      "Model trained for MDIA, MSE: 0.6751\n",
      "Model trained for MDKA, MSE: 8637.6169\n",
      "Model trained for MDKI, MSE: 2.9247\n",
      "Model trained for MDLN, MSE: 8.0192\n",
      "Model trained for MDRN, MSE: 0.1918\n",
      "Model trained for MEDC, MSE: 834.3392\n",
      "Model trained for MEDS, MSE: 2.0669\n",
      "Model trained for MEGA, MSE: 19190.5445\n",
      "Model trained for MEJA, MSE: 34.4166\n",
      "Model trained for MENN, MSE: 0.4562\n",
      "Model trained for MERK, MSE: 3159.5028\n",
      "Model trained for META, MSE: 34.2078\n",
      "Model trained for MFIN, MSE: 1035.7962\n",
      "Model trained for MFMI, MSE: 551.6998\n",
      "Model trained for MGLV, MSE: 11.1904\n",
      "Model trained for MGNA, MSE: 0.6303\n",
      "Model trained for MGRO, MSE: 271.9934\n",
      "Model trained for MHKI, MSE: 5928.3867\n",
      "Model trained for MICE, MSE: 150.6609\n",
      "Model trained for MIDI, MSE: 110.9454\n",
      "Model trained for MIKA, MSE: 4020.0652\n",
      "Model trained for MINA, MSE: 4.4569\n",
      "Model trained for MIRA, MSE: 0.4473\n",
      "Model trained for MITI, MSE: 89.2167\n",
      "Model trained for MKAP, MSE: 20.1605\n",
      "Model trained for MKNT, MSE: 0.3695\n",
      "Model trained for MKPI, MSE: 338436.6150\n",
      "Model trained for MKTR, MSE: 4.9639\n",
      "Model trained for MLBI, MSE: 21811.6094\n",
      "Model trained for MLIA, MSE: 126.3288\n",
      "Model trained for MLPL, MSE: 151.6988\n",
      "Model trained for MLPT, MSE: 2455.7437\n",
      "Model trained for MMIX, MSE: 41.4750\n",
      "Model trained for MMLP, MSE: 80.1098\n",
      "Model trained for MNCN, MSE: 330.9730\n",
      "Model trained for MOLI, MSE: 236.1803\n",
      "Model trained for MORA, MSE: 22.0233\n",
      "Model trained for MPIX, MSE: 9.3859\n",
      "Model trained for MPMX, MSE: 335.1836\n",
      "Model trained for MPOW, MSE: 6.6499\n",
      "Model trained for MPPA, MSE: 280.7435\n",
      "Model trained for MPRO, MSE: 26818.8550\n",
      "Model trained for MPXL, MSE: 62.3594\n",
      "Model trained for MRAT, MSE: 318.0929\n",
      "Model trained for MREI, MSE: 20731.1775\n",
      "Model trained for MSIE, MSE: 0.6924\n",
      "Model trained for MSIN, MSE: 5823.5847\n",
      "Model trained for MSJA, MSE: 35.5283\n",
      "Model trained for MSKY, MSE: 260.1415\n",
      "Model trained for MSTI, MSE: 3154.9911\n",
      "Model trained for MTDL, MSE: 154.9382\n",
      "Model trained for MTEL, MSE: 123.6767\n",
      "Model trained for MTFN, MSE: 0.0811\n",
      "Model trained for MTLA, MSE: 59.1298\n",
      "Model trained for MTMH, MSE: 686.0518\n",
      "Model trained for MTPS, MSE: 1.2941\n",
      "Model trained for MTRA, MSE: 0.0515\n",
      "Model trained for MTSM, MSE: 234.9072\n",
      "Model trained for MTWI, MSE: 15.6326\n",
      "Model trained for MUTU, MSE: 3.6159\n",
      "Model trained for MYOH, MSE: 728.5022\n",
      "Model trained for MYOR, MSE: 2092.1164\n",
      "Model trained for MYRX, MSE: 1.1634\n",
      "Model trained for MYRXP, MSE: 0.0108\n",
      "Model trained for MYTX, MSE: 15.4174\n",
      "Model trained for NANO, MSE: 0.6712\n",
      "Model trained for NASA, MSE: 0.5424\n",
      "Model trained for NASI, MSE: 31.9297\n",
      "Model trained for NATO, MSE: 138.7170\n",
      "Model trained for NAYZ, MSE: 0.8336\n",
      "Model trained for NCKL, MSE: 802.1596\n",
      "Model trained for NELY, MSE: 188.2169\n",
      "Model trained for NETV, MSE: 8.1732\n",
      "Model trained for NFCX, MSE: 43600.8230\n",
      "Model trained for NICE, MSE: 590.2419\n",
      "Model trained for NICK, MSE: 32.9723\n",
      "Model trained for NICL, MSE: 127.4442\n",
      "Model trained for NIKL, MSE: 391.7161\n",
      "Model trained for NINE, MSE: 0.4571\n",
      "Model trained for NIPS, MSE: 0.0022\n",
      "Model trained for NIRO, MSE: 5.3400\n",
      "Model trained for NISP, MSE: 208.4039\n",
      "Model trained for NOBU, MSE: 286.8117\n",
      "Model trained for NPGF, MSE: 3.6186\n",
      "Model trained for NRCA, MSE: 26.1825\n",
      "Model trained for NSSS, MSE: 7.2753\n",
      "Model trained for NTBK, MSE: 6.8239\n",
      "Model trained for NUSA, MSE: 0.1147\n",
      "Model trained for NZIA, MSE: 41.5133\n",
      "Model trained for OASA, MSE: 56.1860\n",
      "Model trained for OBMD, MSE: 33.9954\n",
      "Model trained for OCAP, MSE: 23.4695\n",
      "Model trained for OILS, MSE: 30.7067\n",
      "Model trained for OKAS, MSE: 41.1805\n",
      "Model trained for OLIV, MSE: 0.4700\n",
      "Model trained for OMED, MSE: 3.6616\n",
      "Model trained for OMRE, MSE: 1452.8085\n",
      "Model trained for OPMS, MSE: 3.6323\n",
      "Model trained for PACK, MSE: 1.8462\n",
      "Model trained for PADA, MSE: 0.3185\n",
      "Model trained for PADI, MSE: 0.9152\n",
      "Model trained for PALM, MSE: 633.2070\n",
      "Model trained for PAMG, MSE: 15.2883\n",
      "Model trained for PANI, MSE: 28337.3696\n",
      "Model trained for PANR, MSE: 173.7114\n",
      "Model trained for PANS, MSE: 1000.8466\n",
      "Model trained for PBID, MSE: 251.4645\n",
      "Model trained for PBRX, MSE: 32.8529\n",
      "Model trained for PBSA, MSE: 38.6469\n",
      "Model trained for PCAR, MSE: 10.1861\n",
      "Model trained for PDES, MSE: 185.2694\n",
      "Model trained for PDPP, MSE: 69.3982\n",
      "Model trained for PEGE, MSE: 1109.0597\n",
      "Model trained for PEHA, MSE: 542.0393\n",
      "Model trained for PEVE, MSE: 37.0382\n",
      "Model trained for PGAS, MSE: 1278.9637\n",
      "Model trained for PGEO, MSE: 674.2530\n",
      "Model trained for PGJO, MSE: 4.2737\n",
      "Model trained for PGLI, MSE: 165.4141\n",
      "Model trained for PGUN, MSE: 92.4968\n",
      "Model trained for PICO, MSE: 6654.4740\n",
      "Model trained for PIPA, MSE: 0.0003\n",
      "Model trained for PJAA, MSE: 211.9234\n",
      "Model trained for PKPK, MSE: 61.6546\n",
      "Model trained for PLAN, MSE: 0.8080\n",
      "Model trained for PLAS, MSE: 0.2517\n",
      "Model trained for PLIN, MSE: 3266.2051\n",
      "Model trained for PMJS, MSE: 5.3853\n",
      "Model trained for PMMP, MSE: 260.6519\n",
      "Model trained for PNBN, MSE: 1569.6809\n",
      "Model trained for PNBS, MSE: 3.5964\n",
      "Model trained for PNGO, MSE: 1846.2462\n",
      "Model trained for PNIN, MSE: 776.0587\n",
      "Model trained for PNLF, MSE: 108.1042\n",
      "Model trained for PNSE, MSE: 633.2958\n",
      "Model trained for POLA, MSE: 1.1168\n",
      "Model trained for POLI, MSE: 632.5030\n",
      "Model trained for POLL, MSE: 139.1766\n",
      "Model trained for POLU, MSE: 1751.8374\n",
      "Model trained for POLY, MSE: 4.0237\n",
      "Model trained for POOL, MSE: 0.1977\n",
      "Model trained for PORT, MSE: 1718.1898\n",
      "Model trained for POSA, MSE: 0.0732\n",
      "Model trained for POWR, MSE: 50.6031\n",
      "Model trained for PPGL, MSE: 3.2917\n",
      "Model trained for PPRE, MSE: 5.6944\n",
      "Model trained for PPRI, MSE: 18.9525\n",
      "Model trained for PPRO, MSE: 0.5308\n",
      "Model trained for PRAS, MSE: 37.9823\n",
      "Model trained for PRAY, MSE: 33.5836\n",
      "Model trained for PRDA, MSE: 18910.4396\n",
      "Model trained for PRIM, MSE: 16.4444\n",
      "Model trained for PSAB, MSE: 35.2395\n",
      "Model trained for PSDN, MSE: 50.6480\n",
      "Model trained for PSGO, MSE: 10.4880\n",
      "Model trained for PSKT, MSE: 9.7398\n",
      "Model trained for PSSI, MSE: 102.1718\n",
      "Model trained for PTBA, MSE: 5484.2500\n",
      "Model trained for PTDU, MSE: 3.2124\n",
      "Model trained for PTIS, MSE: 520.5834\n",
      "Model trained for PTMP, MSE: 186.2953\n",
      "Model trained for PTPP, MSE: 500.9401\n",
      "Model trained for PTPS, MSE: 425.5952\n",
      "Model trained for PTPW, MSE: 86.8571\n",
      "Model trained for PTRO, MSE: 15748.6995\n",
      "Model trained for PTSN, MSE: 44.4458\n",
      "Model trained for PTSP, MSE: 32702.2231\n",
      "Model trained for PUDP, MSE: 643.1005\n",
      "Model trained for PURA, MSE: 0.8464\n",
      "Model trained for PURE, MSE: 0.6773\n",
      "Model trained for PURI, MSE: 578.2320\n",
      "Model trained for PWON, MSE: 95.0415\n",
      "Model trained for PYFA, MSE: 2028.5859\n",
      "Model trained for PZZA, MSE: 34.8858\n",
      "Model trained for RAAM, MSE: 440.2646\n",
      "Model trained for RAFI, MSE: 0.0955\n",
      "Model trained for RAJA, MSE: 969.3745\n",
      "Model trained for RALS, MSE: 235.6755\n",
      "Model trained for RANC, MSE: 1129.4171\n",
      "Model trained for RBMS, MSE: 5.2706\n",
      "Model trained for RCCC, MSE: 37.2300\n",
      "Model trained for RDTX, MSE: 79512.0471\n",
      "Model trained for REAL, MSE: 0.9276\n",
      "Model trained for RELF, MSE: 1.0196\n",
      "Model trained for RELI, MSE: 538.3604\n",
      "Model trained for RGAS, MSE: 29.4208\n",
      "Model trained for RICY, MSE: 13.5478\n",
      "Model trained for RIGS, MSE: 304.2728\n",
      "Model trained for RIMO, MSE: 2.1280\n",
      "Model trained for RISE, MSE: 44.9204\n",
      "Model trained for RMKE, MSE: 139.0701\n",
      "Model trained for RMKO, MSE: 26.1323\n",
      "Model trained for ROCK, MSE: 24.9360\n",
      "Model trained for RODA, MSE: 12.8208\n",
      "Model trained for RONY, MSE: 420.9995\n",
      "Model trained for ROTI, MSE: 442.3993\n",
      "Model trained for RSCH, MSE: 238.8712\n",
      "Model trained for RSGK, MSE: 328.8257\n",
      "Model trained for RUIS, MSE: 78.1784\n",
      "Model trained for RUNS, MSE: 5.9427\n",
      "Model trained for SAFE, MSE: 72.8355\n",
      "Model trained for SAGE, MSE: 0.2685\n",
      "Model trained for SAME, MSE: 78.9560\n",
      "Model trained for SAMF, MSE: 182.3453\n",
      "Model trained for SAPX, MSE: 1657.6428\n",
      "Model trained for SATU, MSE: 23.5134\n",
      "Model trained for SBAT, MSE: 0.6118\n",
      "Model trained for SBMA, MSE: 20.8771\n",
      "Model trained for SCCO, MSE: 80825.9960\n",
      "Model trained for SCMA, MSE: 76.0596\n",
      "Model trained for SCNP, MSE: 74.8612\n",
      "Model trained for SCPI, MSE: 6.6592\n",
      "Model trained for SDMU, MSE: 15.8519\n",
      "Model trained for SDPC, MSE: 63.0188\n",
      "Model trained for SDRA, MSE: 287.1431\n",
      "Model trained for SEMA, MSE: 8.7327\n",
      "Model trained for SFAN, MSE: 272.1039\n",
      "Model trained for SGER, MSE: 8768.4317\n",
      "Model trained for SGRO, MSE: 1010.8588\n",
      "Model trained for SHID, MSE: 10754.0757\n",
      "Model trained for SHIP, MSE: 1223.5821\n",
      "Model trained for SICO, MSE: 5.6789\n",
      "Model trained for SIDO, MSE: 192.4338\n",
      "Model trained for SILO, MSE: 2934.0905\n",
      "Model trained for SIMA, MSE: 2.4696\n",
      "Model trained for SIMP, MSE: 32.7336\n",
      "Model trained for SINI, MSE: 3608.0397\n",
      "Model trained for SIPD, MSE: 3011.2855\n",
      "Model trained for SKBM, MSE: 197.8310\n",
      "Model trained for SKLT, MSE: 121.8382\n",
      "Model trained for SKRN, MSE: 916.1244\n",
      "Model trained for SKYB, MSE: 55.7576\n",
      "Model trained for SLIS, MSE: 72.7746\n",
      "Model trained for SMAR, MSE: 6692.1441\n",
      "Model trained for SMBR, MSE: 75.8838\n",
      "Model trained for SMCB, MSE: 1031.9513\n",
      "Model trained for SMDM, MSE: 60.0720\n",
      "Model trained for SMDR, MSE: 102.2673\n",
      "Model trained for SMGA, MSE: 4.5707\n",
      "Model trained for SMGR, MSE: 33361.2584\n",
      "Model trained for SMIL, MSE: 33.0682\n",
      "Model trained for SMKL, MSE: 91.7453\n",
      "Model trained for SMKM, MSE: 3.8733\n",
      "Model trained for SMLE, MSE: 152.3804\n",
      "Model trained for SMMA, MSE: 77996.8350\n",
      "Model trained for SMMT, MSE: 755.9591\n",
      "Model trained for SMRA, MSE: 403.4360\n",
      "Model trained for SMRU, MSE: 0.2089\n",
      "Model trained for SMSM, MSE: 1240.2079\n",
      "Model trained for SNLK, MSE: 875.8047\n",
      "Model trained for SOCI, MSE: 14.3521\n",
      "Model trained for SOFA, MSE: 0.3574\n",
      "Model trained for SOHO, MSE: 79.4089\n",
      "Insufficient data to train model for SOLA.\n",
      "Model trained for SONA, MSE: 5816.3976\n",
      "Model trained for SOSS, MSE: 273.4211\n",
      "Model trained for SOTS, MSE: 337.0672\n",
      "Model trained for SOUL, MSE: 1.2079\n",
      "Model trained for SPMA, MSE: 138.5996\n",
      "Model trained for SPTO, MSE: 30.7989\n",
      "Model trained for SQMI, MSE: 29.5268\n",
      "Model trained for SRAJ, MSE: 674.1711\n",
      "Model trained for SRIL, MSE: 0.3082\n",
      "Model trained for SRSN, MSE: 1.9649\n",
      "Model trained for SRTG, MSE: 4337.0805\n",
      "Model trained for SSIA, MSE: 265.3112\n",
      "Model trained for SSMS, MSE: 1439.9855\n",
      "Model trained for SSTM, MSE: 460.8316\n",
      "Model trained for STAA, MSE: 146.8239\n",
      "Model trained for STAR, MSE: 11.6942\n",
      "Model trained for STRK, MSE: 0.1850\n",
      "Model trained for STTP, MSE: 103826.2597\n",
      "Model trained for SUGI, MSE: 0.0096\n",
      "Model trained for SULI, MSE: 24.5432\n",
      "Model trained for SUNI, MSE: 197.8731\n",
      "Model trained for SUPR, MSE: 1422963.2132\n",
      "Model trained for SURE, MSE: 734.7376\n",
      "Model trained for SURI, MSE: 1343.3182\n",
      "Model trained for SWAT, MSE: 15.8950\n",
      "Model trained for SWID, MSE: 1.1932\n",
      "Model trained for TALF, MSE: 163.5649\n",
      "Model trained for TAMA, MSE: 2.3039\n",
      "Model trained for TAMU, MSE: 0.5798\n",
      "Model trained for TAPG, MSE: 150.9140\n",
      "Model trained for TARA, MSE: 0.3764\n",
      "Model trained for TAXI, MSE: 0.2084\n",
      "Model trained for TAYS, MSE: 10.1804\n",
      "Model trained for TBIG, MSE: 2281.4511\n",
      "Model trained for TBLA, MSE: 223.5024\n",
      "Model trained for TBMS, MSE: 609.9853\n",
      "Model trained for TCID, MSE: 4004.5294\n",
      "Model trained for TCPI, MSE: 45730.5968\n",
      "Model trained for TDPM, MSE: 0.0001\n",
      "Model trained for TEBE, MSE: 101.2175\n",
      "Model trained for TECH, MSE: 145.7138\n",
      "Model trained for TELE, MSE: 1.4840\n",
      "Model trained for TFAS, MSE: 13889.1000\n",
      "Model trained for TFCO, MSE: 533.2151\n",
      "Model trained for TGKA, MSE: 30570.0693\n",
      "Model trained for TGRA, MSE: 0.7797\n",
      "Model trained for TGUK, MSE: 44.2577\n",
      "Model trained for TIFA, MSE: 361.9495\n",
      "Model trained for TINS, MSE: 1895.6731\n",
      "Model trained for TIRA, MSE: 236.3795\n",
      "Model trained for TIRT, MSE: 10.6088\n",
      "Model trained for TKIM, MSE: 82803.6688\n",
      "Model trained for TLDN, MSE: 4.2434\n",
      "Model trained for TLKM, MSE: 3811.1685\n",
      "Model trained for TMAS, MSE: 154.5260\n",
      "Model trained for TMPO, MSE: 25.4701\n",
      "Model trained for TNCA, MSE: 148.6381\n",
      "Model trained for TOBA, MSE: 998.2329\n",
      "Model trained for TOOL, MSE: 1.2545\n",
      "Model trained for TOPS, MSE: 0.4267\n",
      "Model trained for TOSK, MSE: 15.3274\n",
      "Model trained for TOTL, MSE: 49.7946\n",
      "Model trained for TOTO, MSE: 21.2912\n",
      "Model trained for TOWR, MSE: 545.8149\n",
      "Model trained for TOYS, MSE: 0.4530\n",
      "Model trained for TPIA, MSE: 11581.1243\n",
      "Model trained for TPMA, MSE: 216.8348\n",
      "Model trained for TRAM, MSE: 0.0945\n",
      "Model trained for TRGU, MSE: 86.8435\n",
      "Model trained for TRIL, MSE: 0.0003\n",
      "Model trained for TRIM, MSE: 67.9433\n",
      "Model trained for TRIN, MSE: 81.8457\n",
      "Model trained for TRIO, MSE: 1.1123\n",
      "Model trained for TRIS, MSE: 114.9394\n",
      "Model trained for TRJA, MSE: 35.5276\n",
      "Model trained for TRON, MSE: 39.2466\n",
      "Model trained for TRST, MSE: 123.6593\n",
      "Model trained for TRUE, MSE: 1.9432\n",
      "Model trained for TRUK, MSE: 4.4392\n",
      "Model trained for TRUS, MSE: 178.5839\n",
      "Model trained for TSPC, MSE: 787.4835\n",
      "Model trained for TUGU, MSE: 956.4759\n",
      "Model trained for TYRE, MSE: 5.0279\n",
      "Model trained for UANG, MSE: 2194.7060\n",
      "Model trained for UCID, MSE: 193.4912\n",
      "Model trained for UDNG, MSE: 13.6268\n",
      "Model trained for UFOE, MSE: 31.6717\n",
      "Model trained for ULTJ, MSE: 567.0280\n",
      "Model trained for UNIC, MSE: 32637.0173\n",
      "Model trained for UNIQ, MSE: 137.9796\n",
      "Model trained for UNIT, MSE: 22.4039\n",
      "Model trained for UNSP, MSE: 22.3834\n",
      "Model trained for UNTD, MSE: 18.0057\n",
      "Model trained for UNTR, MSE: 321368.4336\n",
      "Model trained for UNVR, MSE: 13525.3745\n",
      "Model trained for URBN, MSE: 31.4237\n",
      "Model trained for UVCR, MSE: 30.4365\n",
      "Model trained for VAST, MSE: 2.4460\n",
      "Model trained for VICI, MSE: 55.1491\n",
      "Model trained for VICO, MSE: 56.9951\n",
      "Model trained for VINS, MSE: 80.8438\n",
      "Model trained for VISI, MSE: 53.0052\n",
      "Model trained for VIVA, MSE: 0.3779\n",
      "Model trained for VKTR, MSE: 70.4153\n",
      "Model trained for VOKS, MSE: 42.4097\n",
      "Model trained for VRNA, MSE: 41.3335\n",
      "Model trained for VTNY, MSE: 99.2766\n",
      "Model trained for WAPO, MSE: 61.2624\n",
      "Model trained for WEGE, MSE: 6.1519\n",
      "Model trained for WEHA, MSE: 42.4195\n",
      "Model trained for WGSH, MSE: 13.3517\n",
      "Model trained for WICO, MSE: 103.7393\n",
      "Model trained for WIDI, MSE: 1.0534\n",
      "Model trained for WIFI, MSE: 16.3160\n",
      "Model trained for WIIM, MSE: 3724.1900\n",
      "Model trained for WIKA, MSE: 975.3406\n",
      "Model trained for WINE, MSE: 62.7486\n",
      "Model trained for WINR, MSE: 5.5016\n",
      "Model trained for WINS, MSE: 175.9766\n",
      "Model trained for WIRG, MSE: 12.4845\n",
      "Model trained for WMPP, MSE: 1.9262\n",
      "Model trained for WMUU, MSE: 1.7068\n",
      "Model trained for WOMF, MSE: 54.5805\n",
      "Model trained for WOOD, MSE: 72.4481\n",
      "Model trained for WOWS, MSE: 1.1556\n",
      "Model trained for WSBP, MSE: 0.8467\n",
      "Model trained for WSKT, MSE: 92.9298\n",
      "Model trained for WTON, MSE: 11.8679\n",
      "Model trained for YELO, MSE: 0.9039\n",
      "Model trained for YPAS, MSE: 1468.5958\n",
      "Model trained for YULE, MSE: 1372.0445\n",
      "Model trained for ZATA, MSE: 5.6960\n",
      "Model trained for ZBRA, MSE: 353.8780\n",
      "Model trained for ZINC, MSE: 0.4095\n",
      "Model trained for ZONE, MSE: 87.2548\n",
      "Model trained for ZYRX, MSE: 16.6539\n",
      "Models saved to file.\n"
     ]
    }
   ],
   "source": [
    "# File to store the models\n",
    "models_file = 'models.pkl'\n",
    "\n",
    "# Check if models are already saved\n",
    "if os.path.exists(models_file):\n",
    "    with open(models_file, 'rb') as f:\n",
    "        models = pickle.load(f)\n",
    "    print('Models loaded from file.')\n",
    "else:\n",
    "    # Get unique tickers\n",
    "    tickers = df['Ticker'].unique()\n",
    "\n",
    "    # Dictionary to store models and MSE\n",
    "    models = {}\n",
    "    for ticker in tickers:\n",
    "        model, mse = train_model_for_ticker(ticker, df)\n",
    "        if model:\n",
    "            models[ticker] = {'model': model, 'mse': mse}\n",
    "            print(f'Model trained for {ticker}, MSE: {mse:.4f}')\n",
    "        else:\n",
    "            print(f'Insufficient data to train model for {ticker}.')\n",
    "    \n",
    "    # Save models to a file\n",
    "    with open(models_file, 'wb') as f:\n",
    "        pickle.dump(models, f)\n",
    "    print('Models saved to file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517ff2c-df7f-4775-af3c-84961e29822a",
   "metadata": {},
   "source": [
    "test GOTO ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f702085f-17f3-4dcb-8a8d-57c17b73a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error for GOTO: 19.2703\n",
      "Last 5 closing prices for GOTO: [67. 65. 66. 66. 66.]\n",
      "Predicted next closing price for GOTO: 67.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\0-projects\\+AI\\MachineLearning\\stock-predict-idx\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_ticker = 'GOTO'\n",
    "\n",
    "# Checking ticker has trained model or not\n",
    "if test_ticker in models:\n",
    "    mse = models[test_ticker]['mse']\n",
    "    print(f'Model Mean Squared Error for {test_ticker}: {mse:.4f}')\n",
    "    \n",
    "    # Get last 5 closing prices\n",
    "    last_5_prices = get_last_5_closing_prices(test_ticker, df)\n",
    "    print(f'Last 5 closing prices for {test_ticker}: {last_5_prices}')\n",
    "    \n",
    "    # Ensure there are enough data points\n",
    "    if len(last_5_prices) == 5:\n",
    "        # Predict next closing price\n",
    "        model = models[test_ticker]['model']\n",
    "        input_features = last_5_prices.reshape(1, -1)\n",
    "        predicted_price = model.predict(input_features)[0]\n",
    "        print(f'Predicted next closing price for {test_ticker}: {predicted_price:.2f}')\n",
    "    else:\n",
    "        print('Not enough data to make a prediction for this ticker.')\n",
    "else:\n",
    "    print(f'No trained model available for {test_ticker}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c227fc5-0cc3-4980-8dad-910c4baefe30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
